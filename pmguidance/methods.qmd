---
title: "Overview of methods for Uncertainty Analysis"
---

::: {.callout-tip collapse="true" appearance="minimal"}
# Identification of potentially relevant sources of uncertainty
<!-- Ch 8 SO -->
:::: {.panel-tabset}
## How
Sources of uncertainty can affect scientific assessment at different levels.

Assessors should be systematic in searching for sources of uncertainty affecting their assessment, by considering every part or component of their assessment in turn and checking whether different types of uncertainty are present.

## Inputs
Uncertainties affecting the inputs used in the scientific assessment are normally identified during the process of appraising the evidence, which is an intrinsic part of scientific assessment.

::: {#start-btn style="font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;"}
[Questions to identify sources of uncertainty affecting inputs](methods_sources_inputs.qmd){.btn .btn-secondary .btn-lg role="button"}
:::

## Assessment methodology
Other sources of uncertainties can be identified in relation to how the evidence is used in the assessment, including any models or reasoning that are used to draw conclusions.

::: {#start-btn style="font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;"}
[Questions to identify sources of uncertainty affecting assessment methodolgoy](methods_sources_methodology.qmd){.btn .btn-secondary .btn-lg role="button"}
:::

::::
:::


::: {.callout-tip collapse="true" appearance="minimal"}
# Methods for obtaining expert judgements
<!-- Ch 9 SO -->
:::: {.panel-tabset}
## Use of expert judgements
All scientific assessment involves the use of expert judgement

Where suitable data are available, this should be used in preference to relying solely on expert judgement. 

When data are strong, uncertainty may be quantified by statistical analysis, and any additional extrapolation or uncertainty addressed by **minimal assessment** (EFSA EKE GD), or collectively as part of the assessment of overall uncertainty.

When data are weak or diverse, it may be better to quantify uncertainty by expert judgement, supported by consideration of the data.

## Formal to less formal EKE
<!-- SO p49 -->
**Formal expert knowledge elicitation (EKE)** have been developed to counter psychological biases and to manage the sharing and aggregation of judgements between experts.

Formal elicitation requires significant time and resources, so it is not feasible to apply it to every source of uncertainty affecting an assessment. Instead, **semi-formal expert knowledge elicitation** can be applied on less important sources of uncertainty. 

Scientific judgements made, usually by a Working Group of experts preparing the assessment, are referred to in this document as judgements by **expert group judgement**.

In practice, there is not a dichotomy between more and less formal approaches to EKE, but rather a continuum.
::::
:::

::: {.callout-tip collapse="true" appearance="minimal"}
# Qualitative methods for analysing uncertainty
<!-- Ch 10 SO -->
:::: {.panel-tabset}
## Use of qualitative methods
Qualitative methods characterise uncertainty using descriptive expression or ordinal scales, without quantitative definitions

<!-- SO p50 -->
They rely on careful use of language and expert judgement.

Qualitative methods may provide a useful aid for experts when making quantitative judgements.

## Examples
::: {#start-btn style="font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;"}
[Qualitative methods](methods_qualitative.qmd){.btn .btn-secondary .btn-lg role="button"}
:::


::::
:::

::: {.callout-tip collapse="true" appearance="minimal"}
# Methods for quantifying uncertainty
<!-- Ch 11 SO -->
:::: {.panel-tabset}
## Use 
text

## Examples
::: {#start-btn style="font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;"}
[Methods to quantify](methods_quantitative.qmd){.btn .btn-secondary .btn-lg role="button"}
:::

::::
:::

::: {.callout-tip collapse="true" appearance="minimal"}
# Investigating influence and sensitivity
<!-- Ch 12 SO -->
:::: {.panel-tabset}

Sensitivity analysis (Annex B.17)

::::
:::

::: {.callout-tip collapse="true" appearance="minimal"}
# Characterisation of overall uncertainty
<!-- Ch 14 SO -->
:::: {.panel-tabset}

There are three options for quantifying the overall uncertainty, depending on the context: 

- Option 1: Make a single judgement of the overall impact of all the identified uncertainties. 

- Option 2: Quantify uncertainty separately in some parts of the assessment, combine them by calculation, and then adjust the result of the calculation by expert judgement to account for the additional uncertainties that are not yet included. 

- Option 3: Quantify uncertainty separately in some parts of the assessment and combine them by calculation, as in Option 2. Then quantify the contribution of the additional uncertainties separately, by expert judgement, and combine it with the previously quantified uncertainty by calculation.

```{r}
#| label: fig-overall-options
#| fig-cap: "Options for characterising overall uncertainty"
#| fig-alt: "Figure showing options for characterising overall uncertainty. Option 1-3 from quickest to most complex."
#| echo: false
knitr::include_graphics("../img/options_for_characterising_overall_uncertainty.png")
```


::::
:::

::: {.callout-tip collapse="true" appearance="minimal"}
# Reporting uncertainty analysis in scientific assessments
<!-- Ch 15 SO -->
:::: {.panel-tabset}

add text
::::
:::
