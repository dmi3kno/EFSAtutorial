{
  "hash": "da41f2d04765afabbcfe4c45c2175c14",
  "result": {
    "markdown": "---\ntitle: \"Overview of methods for Uncertainty Analysis\"\n---\n\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Identification of potentially relevant sources of uncertainty\n<!-- Ch 8 SO -->\n:::: {.panel-tabset}\n## How\nSources of uncertainty can affect scientific assessment at different levels.\n\nAssessors should be systematic in searching for sources of uncertainty affecting their assessment, by considering every part or component of their assessment in turn and checking whether different types of uncertainty are present.\n\n## Inputs\nUncertainties affecting the inputs used in the scientific assessment are normally identified during the process of appraising the evidence, which is an intrinsic part of scientific assessment.\n\n::: {#start-btn style=\"font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;\"}\n[Questions to identify sources of uncertainty affecting inputs](methods_sources_inputs.qmd){.btn .btn-secondary .btn-lg role=\"button\"}\n:::\n\n## Assessment methodology\nOther sources of uncertainties can be identified in relation to how the evidence is used in the assessment, including any models or reasoning that are used to draw conclusions.\n\n::: {#start-btn style=\"font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;\"}\n[Questions to identify sources of uncertainty affecting assessment methodolgoy](methods_sources_methodology.qmd){.btn .btn-secondary .btn-lg role=\"button\"}\n:::\n\n::::\n:::\n\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Methods for obtaining expert judgements\n<!-- Ch 9 SO -->\n:::: {.panel-tabset}\n## Use of expert judgements\nAll scientific assessment involves the use of expert judgement\n\nWhere suitable data are available, this should be used in preference to relying solely on expert judgement. \n\nWhen data are strong, uncertainty may be quantified by statistical analysis, and any additional extrapolation or uncertainty addressed by **minimal assessment** (EFSA EKE GD), or collectively as part of the assessment of overall uncertainty.\n\nWhen data are weak or diverse, it may be better to quantify uncertainty by expert judgement, supported by consideration of the data.\n\n## Formal to less formal EKE\n<!-- SO p49 -->\n**Formal expert knowledge elicitation (EKE)** have been developed to counter psychological biases and to manage the sharing and aggregation of judgements between experts.\n\nFormal elicitation requires significant time and resources, so it is not feasible to apply it to every source of uncertainty affecting an assessment. Instead, **semi-formal expert knowledge elicitation** can be applied on less important sources of uncertainty. \n\nScientific judgements made, usually by a Working Group of experts preparing the assessment, are referred to in this document as judgements by **expert group judgement**.\n\nIn practice, there is not a dichotomy between more and less formal approaches to EKE, but rather a continuum.\n::::\n:::\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Qualitative methods for analysing uncertainty\n<!-- Ch 10 SO -->\n:::: {.panel-tabset}\n## Use of qualitative methods\nQualitative methods characterise uncertainty using descriptive expression or ordinal scales, without quantitative definitions\n\n<!-- SO p50 -->\nThey rely on careful use of language and expert judgement.\n\nQualitative methods may provide a useful aid for experts when making quantitative judgements.\n\n## Examples\n::: {#start-btn style=\"font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;\"}\n[Qualitative methods](methods_qualitative.qmd){.btn .btn-secondary .btn-lg role=\"button\"}\n:::\n\n\n::::\n:::\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Methods for quantifying uncertainty\n<!-- Ch 11 SO -->\n:::: {.panel-tabset}\n## Use \ntext\n\n## Examples\n::: {#start-btn style=\"font-family: 'Roboto Condensed', Roboto, sans-serif; text-align: center;\"}\n[Methods to quantify](methods_quantitative.qmd){.btn .btn-secondary .btn-lg role=\"button\"}\n:::\n\n::::\n:::\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Investigating influence and sensitivity\n<!-- Ch 12 SO -->\n:::: {.panel-tabset}\n\nSensitivity analysis (Annex B.17)\n\n::::\n:::\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Characterisation of overall uncertainty\n<!-- Ch 14 SO -->\n:::: {.panel-tabset}\n\nThere are three options for quantifying the overall uncertainty, depending on the context: \n\n- Option 1: Make a single judgement of the overall impact of all the identified uncertainties. \n\n- Option 2: Quantify uncertainty separately in some parts of the assessment, combine them by calculation, and then adjust the result of the calculation by expert judgement to account for the additional uncertainties that are not yet included. \n\n- Option 3: Quantify uncertainty separately in some parts of the assessment and combine them by calculation, as in Option 2. Then quantify the contribution of the additional uncertainties separately, by expert judgement, and combine it with the previously quantified uncertainty by calculation.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Options for characterising overall uncertainty](../img/options_for_characterising_overall_uncertainty.png){#fig-overall-options fig-alt='Figure showing options for characterising overall uncertainty. Option 1-3 from quickest to most complex.' width=1312}\n:::\n:::\n\n\n\n::::\n:::\n\n::: {.callout-tip collapse=\"true\" appearance=\"minimal\"}\n# Reporting uncertainty analysis in scientific assessments\n<!-- Ch 15 SO -->\n:::: {.panel-tabset}\n\nadd text\n::::\n:::\n",
    "supporting": [
      "methods_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}