[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EFSA Tutorial",
    "section": "",
    "text": "Warning\n\n\n\nTHIS PAGE IS CURRENTLY UNDER CONSTRUCTION\n\n\n \n\n\n\n\n\n \n\nSTART HERE\n\n \n\nLearn more about principles and methods for uncertainty analysis and communication of uncertainty in scientific assessments."
  },
  {
    "objectID": "implementationexpressions.html",
    "href": "implementationexpressions.html",
    "title": "Expressions of Uncertainty",
    "section": "",
    "text": "Here we will have the interactive data table of examples. Currently, we plan to have the following fields in the table:\n\nTitle\nDOI\nPanel\nExpression of uncertainty (from the nine expressions)\nQuantitative method for uncertainty analysis\nQualitative method for uncertainty analysis\nDescription\n\nThe dataframe below is provided as a placeholder."
  },
  {
    "objectID": "uaguidance/dividing.html",
    "href": "uaguidance/dividing.html",
    "title": "Dividing the assessment into parts",
    "section": "",
    "text": "Often an assessment will comprise a number of main parts (e.g. exposure and hazard in a chemical risk assessment) and smaller, subsidiary parts (e.g. individual parameters, studies, or lines of evidence within the exposure or hazard assessment).\nThe uncertainty analysis may also be divided into parts. Assessors should choose at what level to conduct it:\n\nEvaluate all uncertainties collectively, for the assessment as a whole.\nDivide the uncertainty analysis into parts, which evaluate uncertainties separately in major parts of the scientific assessment (e.g. exposure and hazard in a risk assessment). Then, combine the parts of the uncertainty analysis and include also any other identified uncertainties that relate to other parts of the scientific assessment as a whole, so as to characterise the overall uncertainty.\nDivide the uncertainty analysis into still smaller parts, corresponding to still smaller parts of the scientific assessment (e.g. every input of a calculation or model). Evaluate uncertainty collectively within each of the smaller parts, combine them into the main parts, and combine those to characterise overall uncertainty for the whole assessment.\n\nIf the uncertainty analysis will be divided into parts, assessors will need to combine them to characterise overall uncertainty. Assessors should define in advance how the parts will be combined, as this will increase transparency and rigour. It is recommended to use a conceptual model diagram (see glossary for explanation) to show how the parts will be combined. The parts may be combined by expert judgement (Section 12.6), or by calculation (Sections 13, 14 or 15) if assessors quantify the uncertainty for each part and can specify an appropriate quantitative or logical model to combine them. Calculation is likely to give more reliable results, but should be weighed against the additional work involved.\nAssessors should judge what is best suited to the needs of each assessment. For example, it may be more efficient to evaluate uncertainty for different parts separately if they require different expertise (e.g. toxicity and exposure). Evaluating all uncertainties collectively (first option in point (2) above) is generally quicker and superficially simpler but requires integrating them all subjectively by expert judgement, which may be less reliable than evaluating different parts of the uncertainty analysis separately, if they are then combined by calculation. For this reason, it is recommended to treat separately those parts of the assessment that are affected by larger uncertainties (identified by a simple initial prioritisation, see Section 8).\nWhen a part of the scientific assessment is treated separately in the uncertainty analysis, it is not necessary to evaluate immediately all of the uncertainties affecting it; some of them can be set to one side and considered later as part of the overall characterisation of uncertainty, if this is more convenient for the assessor. However, it is recommended that only the lesser uncertainties are deferred to the overall characterisation, since it will be more reliable to combine the larger uncertainties by calculation.\nWhen the scientific assessment includes a quantitative or logical model, assessors may find it convenient to quantify uncertainty separately for every parameter of the model. In such cases, it will still be necessary to identify additional uncertainties that are not quantified within the model, e.g. uncertainties relating to the structure of the model (see Section 7.2) and take them into account in the characterisation of overall uncertainty (Section 16). In other cases, assessors might find it sufficient to analyse all the uncertainties affecting a model collectively (simplest option in point (2) above), or for major parts of the model without separating the individual parameters (intermediate option in point (2))."
  },
  {
    "objectID": "uaguidance/reporting.html",
    "href": "uaguidance/reporting.html",
    "title": "Reporting uncertainty analysis",
    "section": "",
    "text": "Section 17"
  },
  {
    "objectID": "uaguidance/figure7.html",
    "href": "uaguidance/figure7.html",
    "title": "Uncertainty analysis for case-specific assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B[Perform the</br>scientific assessment</br>and uncertainty analysis</br>together] \n  B --> K[Quantify uncertainty</br>for each part of</br>the uncertainty analysis]\n  B --> C[Evaluate uncertainty</br>for each part,</br>qualitatively or quantitatively]\n  K --> L[Combine the parts</br>using a suitable</br>logic model]\n  subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    D[Decide how</br>to express</br>the uncertainty] --> E[Elicit</br>a probability judgement</br>for the overall</br>uncertainty]\n    E --> F[Check for</br>and describe</br>any unquantified</br>uncertainties]\n    M[Take account</br>of the contribution</br>of any additional</br>uncertainties] --> N[Check for</br>and describe any</br>unquantified uncertainties]\n  end\n  L-->M\n    C --> D\n    F --> G[[Report conclusion</br>in form needed</br>by decision makers,</br>and detailed analysis</br>in opinion</br>or annex]]\n    N --> G  \n  click A \"figure5.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click Z \"figure3.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/figure10.html",
    "href": "uaguidance/figure10.html",
    "title": "Uncertainty analysis for case-specific assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B[Perform the</br>scientific assessment</br>and uncertainty analysis</br>together] \n  B --> C[Do you want</br>to try the simpler</br>option of</br>using only bounded</br>probabilities?]\n  C --Yes-->D[Quantify uncertainty</br>for each part of</br>the uncertainty analysis,</br>using probability bounds for</br>both uncertainty and variability]\n  D--> F[Combine the parts</br>by probability bounds</br> calculation]\n  C --No -->E[Quantify uncertainty</br>for each part of</br>the uncertainty analysis,</br>using 2D distributions</br>for variable quantities]\n  E --> G[Combine the parts</br>by 2D Monte Carlo</br>simulation]\n    subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    H[Take account</br>of the contribution</br>of any additional</br>uncertainties] --> I[Check for</br>and describe any</br>unquantified uncertainties]\n  end\n  F & G --> ov\n  ov--> J[[Report conclusion</br>in form needed</br>by decision makers,</br>and detailed analysis</br>in opinion</br>or annex]]\n  click A \"figure5.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/prioritizing.html",
    "href": "uaguidance/prioritizing.html",
    "title": "Prioritizing uncertainties",
    "section": "",
    "text": "Prioritising sources of uncertainty may be useful at different stages of the assessment and uncertainty analysis. In the early stages, it can be used to select more important uncertainties to be analysed by more refined methods, e.g. to be evaluated individually rather than collectively, to be expressed with probabilities or distributions rather than bounds, to be elicited by more rather than less formal methods, etc. Prioritisation can also be used during the course of an assessment, to identify parts of the assessment where it might be beneficial to search for more data, use more complex models, or invite additional experts. At the end of the assessment, it may be useful to prioritise uncertainties to identify potential areas for further research.\nPrioritisation, at any stage of the assessment, should be based on the contribution of individual sources of uncertainty to the uncertainty of the assessment as a whole. This is determined by a combination of the magnitude of each uncertainty and how much it affects the result of the assessment, both of which need to be taken into account [SO5.7].\nThe relative influence of different uncertainties can be assessed in a simple and approximate way using qualitative methods based on expert judgement. An ordinal scale can be used to express expert judgements of the magnitude and/or direction of impact of each uncertainty on the question or quantity of interest, as in ‘uncertainty tables’ [SO10.5 and 10.6]. Or separate ordinal scales could be used to express judgements of the magnitude of each uncertainty and its influence, as in the Numeral, Unit, Spread, Assessment and Pedigree (NUSAP) approach [SO10.4].\nWhen the assessment involves a calculation or quantitative model, the contributions of uncertainties about the model inputs can be assessed rigorously by sensitivity analysis. These range from simple ‘what if’ calculations and ‘minimal assessment’ (EFSA, 2014a) to sophisticated sensitivity analyses [see SO12] for which specialist help might be required (Section 1.7). The influence of uncertainties relating to choices regarding the structure of the model or assessment may need to be addressed by repeating the assessment with alternative choices. Prioritisation at the early stages of an assessment must necessarily be done by expert judgement or by sensitivity analysis using a preliminary model, as the assessment model is still under development."
  },
  {
    "objectID": "uaguidance/figure1.html",
    "href": "uaguidance/figure1.html",
    "title": "Uncertainty analysis for standardised assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TD\n  A([< BACK]) --> B{Check every part</br>of assessment</br>for nonstandard</br>uncertainties}\n  B -- None identified --> C[[Document in the opinion that</br>non-standard uncertainties</br>were checked for</br>and none were identified]]\n  B --One or more identified --> Z([NEXT >])\n  click A \"../uncertaintyanalysis.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click Z \"figure2.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/overall.html",
    "href": "uaguidance/overall.html",
    "title": "Characterising overall uncertainty",
    "section": "",
    "text": "Section 16"
  },
  {
    "objectID": "uaguidance/figure11.html",
    "href": "uaguidance/figure11.html",
    "title": "Uncertainty analysis for urgent assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B[Conduct the assessment,</br>listing uncertainties</br>you identify] \n  B --> C[Ensure the question</br>or quantity of interest</br>is well-defined]\n  C --> D[Decide how to</br>express the uncertainty]\n  D --> E[Quickly check</br>the assessment for</br>additional uncertainties]\n  E --> ov\n  subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n F[Elicit</br>a probability judgement</br>for the overall</br>uncertainty] --> G[Check for</br>and describe</br>any unquantified</br>uncertainties]\n  end\n    ov --> H[[Report conclusion</br>in form needed</br>by decision makers,</br>and detailed analysis</br>in opinion</br>or annex]]\n  \n  click A \"../uncertaintyanalysis.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/identifying.html",
    "href": "uaguidance/identifying.html",
    "title": "Identifying uncertainties",
    "section": "",
    "text": "Standard uncertainties are those that are considered (implicitly or explicitly) to be addressed by the provisions of a standardised procedure or standardised assessment element. For example, uncertainties due to within and between species differences in toxicity are often addressed by a default factor of 100 in chemical risk assessment.\nAll other uncertainties are non-standard uncertainties. These include any deviations from a standardised procedure or standardised assessment element that lead to uncertainty regarding the result of the procedure.\n\nBoth standard and non-standard uncertainties may be found in any type of assessment, but the proportions vary. It is recommended that EFSA’s Panels include lists of standard uncertainties within the documentation for standard procedures, as this will help assessors to distinguish standard and non-standard uncertainties."
  },
  {
    "objectID": "uaguidance/identifying.html#procedure-for-identifying-uncertainties",
    "href": "uaguidance/identifying.html#procedure-for-identifying-uncertainties",
    "title": "Identifying uncertainties",
    "section": "Procedure for identifying uncertainties",
    "text": "Procedure for identifying uncertainties\n\nEvery assessment must say what sources of uncertainty have been identified.\nAssessors should systematically examine every part of their assessment for uncertainties, including both the inputs to the assessment (e.g. data, estimates, other evidence) and the methods used in the assessment (e.g. statistical methods, calculations or models, reasoning, expert judgement), to minimise the risk that important uncertainties are overlooked.\nUncertainties affecting assessment inputs are identified when appraising the evidence retrieved from literature or from existing databases.\nUncertainties affecting the methods used in the assessment are generally not addressed by existing frameworks for evidence appraisal. It is therefore recommended that assessors use the right column of Table 1 (referring to [SO8.1] for details and explanation) as a guide to what types of uncertainty to look for in the methods of their assessment.\nAssessors are advised to avoid spending excessive time trying to match uncertainties to the types listed in Table 1 or other frameworks: the purpose of the lists is to facilitate identification of uncertainties, not to classify them.\nAssessors should determine which of the uncertainties they identify in an assessment are standard and which are non-standard (Section 7.1), as this will affect their treatment in subsequent stages of the uncertainty analysis."
  },
  {
    "objectID": "uaguidance/futureinvestigation.html",
    "href": "uaguidance/futureinvestigation.html",
    "title": "Prioritising uncertainties for future investigation",
    "section": "",
    "text": "Section 8"
  },
  {
    "objectID": "uaguidance/characterizing.html",
    "href": "uaguidance/characterizing.html",
    "title": "Characterising uncertainty for parts of the uncertainty analysis",
    "section": "",
    "text": "Section 11-12"
  },
  {
    "objectID": "uaguidance/figure2.html",
    "href": "uaguidance/figure2.html",
    "title": "Standardized Assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B{Are assessors able</br>to evaluate</br>the non-standard</br> uncertainties</br> collectively?}\n      B -- Yes --> C[Define the question</br>or quantity of interest]\n      C --> ov\n  B -- No --> Z([NEXT >])\n  subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    D[Decide</br>how to express</br>the uncertainty] --> E[Elicit</br>a probability judgement</br>for the overall</br>uncertainty]\n    E --> F[Check for</br>and describe</br>any unquantified</br>uncertainties]\n  end\n    ov --> G[[Report conclusion</br>in form needed</br>by decision makers,</br>and detailed analysis</br>in opinion</br>or annex]]\n  \n  click A \"figure1.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click Z \"figure3.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/figure3.html",
    "href": "uaguidance/figure3.html",
    "title": "Standardized Assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    D[Take account</br>of the contribution</br>of any additional uncertainties] --> E[Check for and</br>describe any </br>unquantified uncertainties]\n  end\n  A([< BACK]) --> B[Divide the uncertainty analysis</br>into convenient parts,</br>define the question or</br>quantity of interest </br>for each part, and</br>an appropriate calculation</br>for combining the parts]\n  B --> C[Elicit probability</br> bounds for each part,</br> and combine probability</br>bounds by calculation]\n  C --> ov\n  ov --> F{Is the result</br>expected to be sufficient</br>for decision-making?}\n  F -- Yes--> G[[Report conclusion</br>in form needed by</br>decision-makers,</br>and detailed analysis</br>in opinion or annex]]\n  F -- No --> Z([NEXT >])\n  click A \"figure2.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click Z \"figure4.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/figure5.html",
    "href": "uaguidance/figure5.html",
    "title": "Uncertainty analysis for case-specific assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TD\n  A([< BACK]) -->  B[Plan your</br>scientific assessment</br>in your usual manner]\n  B --> C[Identify uncertainties</br>systematically in all</br>parts of your assessment]\n  C --> D{Do you want</br>to evaluate</br>all uncertainties</br>collectively in</br>a single step?}\n  D--Yes--> E([NEXT >])\n  D--No--> F[Divide the uncertainty analysis</br>into convenient parts,</br>define the question</br>or quantity of interest</br>for each part,</br>and an appropriate conceptual</br>model for combining the parts]\n  F-->G{Do all parts</br>relate to</br>yes/no questions?}\n  G--Yes-->H([NEXT >])\n  G--No--> I{Do any part</br>relate to</br>variable quantities}\n  I --Yes--> K([NEXT >])\n  I --No--> L([NEXT >])\n  click A \"../uncertaintyanalysis.html\" \"Go Back\" _self\n  click E \"figure6.html\" \"Go Forward\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click H \"figure7.html\" \"Go Forward\" _self\n  click L \"figure9.html\" \"Go Forward\" _self\n  click K \"figure10.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,E,H,L,K dark"
  },
  {
    "objectID": "uaguidance/figure12.html",
    "href": "uaguidance/figure12.html",
    "title": "Uncertainty analysis for urgent assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B[Ensure the inputs,</br>methods and outputs</br>of the standard procedure</br>are well-defined] \n  B --> C[Define the class</br>of problems or applications</br>this procedure</br>will be used for]\n  C --> D[Agree the management</br>objective for the</br>standard procedure]\n  D --> E[Design and perform</br>a scientific assessment</br>and uncertainty analysis</br>of the extent to which</br>the standard procedure</br>will achieve the management objective]\n  E --> F{Is there</br>sufficient probability</br>of achieving</br>the management objective</br>to an acceptable extent?}\n  F -- Yes --> G[Document the assessment</br>and uncertainty analysis</br>of the standard procedure]\n  F -- No --> H[Modify the standard</br>procedure in ways that</br>you expect to achieve</br>the management objective]\n  H --> I[Redo the assessment</br>and uncertainty analysis</br>for the modified procedure]\n  I -.-> E\n  G --> J[[Make the standard</br>procedure available</br>for use]]\n  \n  \n  click A \"../uncertaintyanalysis.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/welldefined.html",
    "href": "uaguidance/welldefined.html",
    "title": "Ensuring that the questions or quantities of interest are well-defined",
    "section": "",
    "text": "In order to evaluate uncertainty, the questions and/or quantities of interest for the assessment must be well-defined. This applies both to the assessment as a whole and to different parts of the uncertainty analysis, if it is separated into parts. Any ambiguity in the definition of questions or quantities of interest will add extra uncertainty and make the evaluation more difficult. When a question or quantity of interest is not already well-defined for the purpose of scientific assessment, assessors should define it well for the purpose of uncertainty analysis.\nA quantity or question of interest is well-defined if, at least in principle, it could be determined in such a way that assessors would be sure to agree on the answer. A practical way to achieve this is by specifying an experiment, study or procedure that could be undertaken, at least in principle, and which would determine the true answer for the question or quantity with certainty [see SO5.1 for more discussion]. For example:\n\na well-defined measure for a quantity of interest, and the time, population or location, and conditions (e.g. status quo or with specified management actions) for which the measure will be considered;\nfor a question of interest, the presence or absence of one or more clearly-defined states, conditions, mechanisms, etc., of interest for the assessment, and the time, population or location, and conditions (e.g. status quo or with specified management actions) for which this will be considered;\nthe result of a clearly-defined scientific study, procedure or calculation, which is established (e.g. in legislation or guidance) as being relevant for the assessment.\n\nWhen drafting the definition of each question or quantity of interest, check each word in turn. Identify words that are ambiguous (e.g. high), or imply a risk management judgement (e.g. negligible, safe). Replace or define them with words that are, as far as possible, unambiguous and free of risk management connotations or, where appropriate, with numbers.\nSometimes the Terms of Reference for an assessment are very open, e.g. requesting a review of the literature on an area of science. In such cases, assessors should seek to ensure the conclusions they produce either refer to well-defined quantities, or contain welldefined statements that can be considered as answers to well-defined questions, in one of the three forms listed above (point 2, options a–c). This is necessary both for transparency and so that assessors can evaluate and express the uncertainty associated with their conclusions."
  },
  {
    "objectID": "uaguidance/figure6.html",
    "href": "uaguidance/figure6.html",
    "title": "Uncertainty analysis for case-specific assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B[Conduct the assessment</br>as planned, noting</br>any further</br>uncertainties you identify] \n  B --> C[Ensure the question</br>or quantity of interest</br>is well-defined]\n  C --> ov\n  subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    D[Decide</br>how to express</br>the uncertainty] --> E[Elicit</br>a probability judgement</br>for the overall</br>uncertainty]\n    E --> F[Check for</br>and describe</br>any unquantified</br>uncertainties]\n  end\n    ov --> G[[Report conclusion</br>in form needed</br>by decision makers,</br>and detailed analysis</br>in opinion</br>or annex]]\n  \n  click A \"figure5.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click Z \"figure3.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/figure9.html",
    "href": "uaguidance/figure9.html",
    "title": "Uncertainty analysis for case-specific assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([< BACK]) --> B[Perform the</br>scientific assessment</br>and uncertainty analysis</br>together] \n  B --> C[Do you want</br>to try the simpler</br>option of</br>using only bounded</br>probabilities?]\n  C --Yes-->D[Obtain probability</br>bounds for each</br>part of the</br>uncertainty analysis]\n  D--> F[Combine the parts</br>by probability bounds</br> calculation]\n  C --No -->E[Obtain a probability</br>or distribution for</br>each part of the</br>uncertainty analysis]\n  E --> G[Combine the parts</br>by 1D Monte Carlo</br>simulation]\n    subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    H[Take account</br>of the contribution</br>of any additional</br>uncertainties] --> I[Check for</br>and describe any</br>unquantified uncertainties]\n  end\n  F & G --> ov\n  ov--> J[[Report conclusion</br>in form needed</br>by decision makers,</br>and detailed analysis</br>in opinion</br>or annex]]\n  click A \"figure5.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C callback \"See Section 17 regarding reporting.\"\n  click Z \"figure3.html\" \"Go Forward\" _self\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/figure4.html",
    "href": "uaguidance/figure4.html",
    "title": "Standardized Assessments",
    "section": "",
    "text": "%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  subgraph ov [Characterisation of overall uncertainty]\n    direction LR\n    D[Take account</br>of the contribution</br>of any additional uncertainties] --> E[Check for and</br>describe any </br>unquantified uncertainties]\n  end\n  A([< BACK]) --> B[Obtain a probability</br> or a distribution</br> for each part of the</br> uncertainty analysis]\n  B --> C[Combine the parts</br> using the calculation</br> chosen earlier]\n  C --> ov\n  ov --> G[[Report conclusion</br>in form needed by</br>decision-makers,</br>and detailed analysis</br>in opinion or annex]]\n  \n  click A \"figure3.html\" \"Go Back\" _self\n  click B callback \"See Section 7.1.\"\n  click C \"figure3.html\" \"See Section 17 regarding reporting.\"\n  click Z \"figure4.html\"\n  classDef dark fill:#0d5caa,stroke:#0d5caa,stroke-width:0px,color:#fff\n  class A,Z dark"
  },
  {
    "objectID": "uaguidance/combining.html",
    "href": "uaguidance/combining.html",
    "title": "Combining uncertainty from different parts of the uncertainty analysis",
    "section": "",
    "text": "Section 13-15"
  },
  {
    "objectID": "comguidance/communicator.html",
    "href": "comguidance/communicator.html",
    "title": "Communication of Uncertainty for Communicators",
    "section": "",
    "text": "1. Did the scientific assessment for this message identify any non-standard uncertainties?\n\n\n\n\n\n\nYesNo\n\n\nIf an unqualified conclusion is required, follow the guidance for unqualified conclusions (see Question 5 here). If an unqualified conclusion is not required, state the result of the standardised procedure in the form expressed by the assessors. Also communicate the uncertainty expressions for this message, consulting the respective guidance boxes.\n\n\nReport the conclusion as expressed by assessors and state that a standardised assessment procedure was followed that takes account of standard uncertainties, and no non-standard uncertainties were identified.\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Does the scientific output list or describe the sources or causes of any uncertainties affecting this message?\n\n\n\n\n\n\nEntryInformed\n\n\n\nState that uncertainties exist, using the wording in the scientific output.\n\n\nExample: “The experts identified limitations in the data on exposure and toxic effects of ZEN and its modified forms” Based on EFSA 2017;15(7):4851\n\n\n\n\nState that uncertainties exist, using the wording in the scientific output.\nInclude in the message a brief description of the sources of uncertainty that have the biggest impact on the respective key messages. (If necessary, consult the assessors to identify these.)\n\n\nExample: “The experts identified limitations in the data on exposure and toxic effects of ZEN and its modified forms, for example (…)” Based on EFSA 2017;15(7):4851\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Is the direction and/or degree of uncertainty expressed verbally (i.e. with terms like ‘low’, ‘medium’, ‘high’) or with symbols (e.g. ‘+’ or ‘-’)?\n\n\n\n\n\n\nEntryInformed\n\n\n\nAvoid altering the wordings used by assessors to describe the direction and/or degree of uncertainty, or factors contributing to uncertainty (Box 2). Always check the rewording with the assessors if you do.\nState clearly what outcomes and conditions this expression of uncertainty refers to (see Box 1).\nMake clear that any uncertainty referred to in the communication has been taken into account in the assessment conclusion.\n\n\nExample: “The Panel noted that there was very high uncertainty about the exposure estimates and took this into account in its conclusion that there is no health concern” Based on EFSA 2017;15(7):4851\n\n\n\nAs for entry level, with the following differences: - Before communicating the uncertainty expression, describe a few examples of the evidence/data that were considered and the uncertainties affecting the assessment. – Optionally, mention specific methods that were used in evaluating the uncertainty. – Optionally, mention factors contributing to the overall uncertainty, including the relative importance of individual sources of uncertainty and things like the relevance and reliability of evidence (e.g. in weight of evidence assessments, see EFSA Scientific Committee 2017). – Clearly distinguish individual sources of uncertainty from overall uncertainty about the assessment conclusions\n\nExample: “The Panel noted that a high proportion of measurements of ZEN and its modified forms in feed were below the limit of detection, leading to very high uncertainty when estimating exposure” Based on EFSA 2017;15(7):4851\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Does this message report an inconclusive assessment outcome?\n\n\n\n\n\n\nEntryInformed\n\n\n\nCommunicate clearly that EFSA is unable to give any conclusion on the quantity or question of interest to which this message refers. If the assessment is inconclusive, this implies that nothing further can be said and therefore the communication should avoid using language that might suggest otherwise.\nIndicate very briefly the sources of uncertainty that contribute most to this outcome (e.g. lack of data, poor quality or limited relevance of data).\n\n\n\n\nDescribe the main sources of uncertainty in more detail, but concisely, following the guidance in Box 2. - Inconclusive assessments are especially likely to include options or requirements for obtaining further data. Communicate these as instructed in Section 3.1.5 on ‘Addressing the uncertainties’.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Do risk managers expect or does legislation require that this message should be expressed as an unqualified conclusion, without any expression of uncertainty?\n\n\n\n\n\n\nEntryInformed\n\n\n\nReport the unqualified conclusion for this message using the same wording as the assessors.\n\n\n\n\nAs for the entry level.\nOptionally, describe briefly how the assessment was made (i.e. what evidence and methods were used to arrive at the conclusions).\nBriefly describe some examples of uncertainties affecting the assessment for this message, as identified in your completed template, consulting Box 4 for guidance on how to communicate this.\nIf the assessment contains any verbal or numerical expression of the impact of the uncertainties as identified in your template, follow the respective guidance in Boxes 6–9 below.\nSay that the assessors took the uncertainties into account when reaching their conclusion(s) for this message.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Is the uncertainty described with numbers as a precise probability?\n\n\n\n\n\n\nEntryInformed\n\n\n\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to (see example below).\n\n\n\n\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to (see example below).\nBefore giving the probability, describe a few examples of the evidence/data that were considered and the uncertainties affecting the assessment, and state that the experts took these into account when assessing their level of certainty. – Optionally, mention specific methods that were used in quantifying the uncertainty, e.g. modelling, statistical analysis, expert knowledge elicitation (EKE), or a combination of these.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7. Is the uncertainty described with numbers as an approximate probability?\n\n\n\n\n\n\nEntryInformed\n\n\n\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to. - An approximate probability may comprise a range of probabilities chosen by the assessors from the approximate probability scale (Table 4), or a different range of probabilities specified by the assessors.\nAlways communicate the quantitative range of probabilities because this expresses the assessors’ conclusion without ambiguity. If a verbal expression is also used, present the quantitative probability first (e.g. ‘66–90% certain (likely)’) because it has been shown that this order leads to more consistent understanding than if the verbal expression is presented first (see Section 3.1)\nTo avoid inconsistency and misunderstanding, do not use the verbal terms in Table 4 to refer to any probabilities or ranges of probabilities other than those shown in this table.\n\n\n\n\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to. - An approximate probability may comprise a range of probabilities chosen by the assessors from the approximate probability scale (Table 4), or a different range of probabilities specified by the assessors.\nAlways communicate the quantitative range of probabilities because this expresses the assessors’ conclusion without ambiguity. If a verbal expression is also used, present the quantitative probability first (e.g. ‘66–90% certain (likely)’) because it has been shown that this order leads to more consistent understanding than if the verbal expression is presented first (see Section 3.1)\nTo avoid inconsistency and misunderstanding, do not use the verbal terms in Table 4 to refer to any probabilities or ranges of probabilities other than those shown in this table.\nBefore giving the probability, describe a few examples of the evidence/data that were considered and the uncertainties affecting the assessment, and state that the experts took these into account when assessing their level of certainty.\nOptionally, mention specific methods that were used in quantifying the uncertainty, e.g. modelling, statistical analysis, expert knowledge elicitation (EKE), or a combination of these.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8. Is the uncertainty described with numbers as a one-dimensional probability distribution?\n\n\n\n\n\n\nEntryInformed\n\n\nEntry level\n\n\nInformed level\n\n\n\n\n\n\n\n\n\n\n\n\n\n9. Is the uncertainty described with numbers as a two-dimensional probability distribution?\n\n\n\n\n\n\nEntryInformed\n\n\nEntry level\n\n\nInformed level"
  },
  {
    "objectID": "comguidance/assessor.html",
    "href": "comguidance/assessor.html",
    "title": "Communication of Uncertainty for Assessors",
    "section": "",
    "text": "1. Did the scientific assessment for this message identify any non-standard uncertainties?\n\n\n\n\n\n\nYesNo\n\n\nIf an unqualified conclusion is required, follow the guidance for unqualified conclusions (see Question 5 here). If an unqualified conclusion is not required, state the result of the standardised procedure in the form expressed by the assessors. Also communicate the uncertainty expressions for this message, consulting the respective guidance boxes.\n\n\nReport the conclusion as expressed by assessors and state that a standardised assessment procedure was followed that takes account of standard uncertainties, and no non-standard uncertainties were identified.\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Does the scientific output list or describe the sources or causes of any uncertainties affecting this message?\n\n\n\n\n\n\nInformedTechnical\n\n\n\nState that uncertainties exist, using the wording in the scientific output.\nInclude in the message a brief description of the sources of uncertainty that have the biggest impact on the respective key messages. (If necessary, consult the assessors to identify these.)\n\n\nExample: “The experts identified limitations in the data on exposure and toxic effects of ZEN and its modified forms, for example (…)” Based on EFSA 2017;15(7):4851\n\n\n\n\nWhen documenting sources of uncertainty in the assessment report, assessors should include brief text descriptions suitable for subsequent use in communications to informed audiences without using specialist technical terms. - Assessors should try to identify which sources of uncertainty have most influence on their conclusions, either by qualitative assessment or by influence or sensitivity analysis UA.\nWhere there is conflicting evidence on an issue, this is a source of uncertainty which must be documented and taken into account in uncertainty analysis, and may be assessed using a weight of evidence approach WE.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Is the direction and/or degree of uncertainty expressed verbally (i.e. with terms like ‘low’, ‘medium’, ‘high’) or with symbols (e.g. ‘+’ or ‘-’)?\n\n\n\n\n\n\nInformedTechnical\n\n\n\nAvoid altering the wordings used by assessors to describe the direction and/or degree of uncertainty, or factors contributing to uncertainty (Box 2). Always check the rewording with the assessors if you do.\nState clearly what outcomes and conditions this expression of uncertainty refers to.\nMake clear that any uncertainty referred to in the communication has been taken into account in the assessment conclusion.\nBefore communicating the uncertainty expression, describe a few examples of the evidence/data that were considered and the uncertainties affecting the assessment.\n\nOptionally, mention specific methods that were used in evaluating the uncertainty.\n\nOptionally, mention factors contributing to the overall uncertainty, including the relative importance of individual sources of uncertainty and things like the relevance and reliability of evidence (e.g. in weight of evidence assessments, see WE).\n\nClearly distinguish individual sources of uncertainty from overall uncertainty about the assessment conclusions.\n\n\nExample: “The Panel noted that a high proportion of measurements of ZEN and its modified forms in feed were below the limit of detection, leading to very high uncertainty when estimating exposure” Based on EFSA 2017;15(7):4851\n\n\n\n\nIf using “+” and “−” or other symbols to indicate the direction and magnitude of uncertainty, accompany these with quantitative definitions of their meaning, as discussed in Annex 5 of PM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Does this message report an inconclusive assessment outcome?\n\n\n\n\n\n\nInformedTechnical\n\n\n\nDescribe the main sources of uncertainty in more detail, but concisely, following the guidance in Box 2. - Inconclusive assessments are especially likely to include options or requirements for obtaining further data. Communicate these as instructed in Section 3.1.5 on ‘Addressing the uncertainties’.\n\n\n\n\nWhen explaining why the assessment is inconclusive, include a description of the key sources of uncertainty that are responsible for this.\n\nIf the assessment is not totally uncertain, try to express what the science can say and quantify the uncertainty unless the risk manager/legislation requires that only unqualified conclusions be given.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Do risk managers expect or does legislation require that this message should be expressed as an unqualified conclusion, without any expression of uncertainty?\n\n\n\n\n\n\nInformedTechnical\n\n\n\nAs for the entry level.\nOptionally, describe briefly how the assessment was made (i.e. what evidence and methods were used to arrive at the conclusions).\nBriefly describe some examples of uncertainties affecting the assessment for this message, as identified in your completed template, consulting Box 4 for guidance on how to communicate this.\nIf the assessment contains any verbal or numerical expression of the impact of the uncertainties as identified in your template, follow the respective guidance in Boxes 6–9 below.\nSay that the assessors took the uncertainties into account when reaching their conclusion(s) for this message.\n\n\n\n\nProvide the information needed for the FAQ required at the entry level communications (see above).\nSpecify what level of certainty is associated with each unqualified conclusion. Risk managers can explain why that level of certainty is appropriate for decisionmaking, if considered necessary. Make this information available to interested parties in suitable ways, e.g. in an FAQ and/or in documentation or guidance on the assessment methodology.\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to (see example below).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Is the uncertainty described with numbers as a precise probability?\n\n\n\n\n\n\nInformedTechnical\n\n\n\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to (see example below).\nBefore giving the probability, describe a few examples of the evidence/data that were considered and the uncertainties affecting the assessment, and state that the experts took these into account when assessing their level of certainty.\nOptionally, mention specific methods that were used in quantifying the uncertainty, e.g. modelling, statistical analysis, expert knowledge elicitation (EKE), or a combination of these.\n\n\n\n\nNo specific guidance for assessors other than the general guidance for assessors in Section 3.2 (above).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7. Is the uncertainty described with numbers as an approximate probability?\n\n\n\n\n\n\nInformedTechnical\n\n\n\nState clearly what the probability refers to, including whether it refers to a numerical estimate or a qualitative conclusion. When the probability refers to a numerical estimate, also state the range of the quantity that the probability refers to. - An approximate probability may comprise a range of probabilities chosen by the assessors from the approximate probability scale (Table 4), or a different range of probabilities specified by the assessors.\nAlways communicate the quantitative range of probabilities because this expresses the assessors’ conclusion without ambiguity. If a verbal expression is also used, present the quantitative probability first (e.g. ‘66–90% certain (likely)’) because it has been shown that this order leads to more consistent understanding than if the verbal expression is presented first (see Section 3.1) • To avoid inconsistency and misunderstanding, do not use the verbal terms in Table 4 to refer to any probabilities or ranges of probabilities other than those shown in this table.\nBefore giving the probability, describe a few examples of the evidence/data that were considered and the uncertainties affecting the assessment, and state that the experts took these into account when assessing their level of certainty.\nOptionally, mention specific methods that were used in quantifying the uncertainty, e.g. modelling, statistical analysis, expert knowledge elicitation (EKE), or a combination of these.\n\n\n\n\nUse different probabilities or ranges from those shown in Table 4 if they better express your judgement (EFSA Scientific Committee et al., 2018a). In such cases, avoid accompanying it with any verbal probability expression because a harmonised interpretation exists only for the terms in Table 4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8. Is the uncertainty described with numbers as a one-dimensional probability distribution?\n\n\n\n\n\n\nInformedTechnical\n\n\nInformed level\n\n\nTechnical level\n\n\n\n\n\n\n\n\n\n\n\n\n\n9. Is the uncertainty described with numbers as a two-dimensional probability distribution?\n\n\n\n\n\n\nInformedTechnical\n\n\nInformed level\n\n\nTechnical level"
  },
  {
    "objectID": "pmguidance/pmanalysis.html",
    "href": "pmguidance/pmanalysis.html",
    "title": "Principles of Uncertainty Analysis",
    "section": "",
    "text": "In this sections you can learn more about the underlying concepts behind the uncertainty analysis guidance."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#definition-of-uncertainty-and-uncertainty-analysis",
    "href": "pmguidance/pmanalysis.html#definition-of-uncertainty-and-uncertainty-analysis",
    "title": "Principles of Uncertainty Analysis",
    "section": "Definition of uncertainty and uncertainty analysis",
    "text": "Definition of uncertainty and uncertainty analysis\n\nUncertainty refers to all types of limitations in available knowledge that affect the range and probability of possible answers to an assessment question.\nAvailable knowledge refers here to the knowledge (evidence, data, etc.) available to assessors at the time the assessment is conducted and within the time and resources agreed for the assessment.\nUncertainty analysis is defined as the process of identifying and characterising uncertainty about questions of interest and/or quantities of interest in a scientific assessment.\nA question or quantity of interest may be the subject of the assessment as a whole, i.e. that which is required by the ToR for the assessment, or it may be the subject of a subsidiary part of the assessment which contributes to addressing the ToR (e.g. exposure and hazard assessment are subsidiary parts of risk assessment)."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#roles-of-assessors-aand-decision-makers",
    "href": "pmguidance/pmanalysis.html#roles-of-assessors-aand-decision-makers",
    "title": "Principles of Uncertainty Analysis",
    "section": "Roles of assessors aand decision-makers",
    "text": "Roles of assessors aand decision-makers\n\nBasic principles for addressing uncertainty in risk analysis are stated in the Codex Working Principles for Risk Analysis:\n\n‘Constraints, uncertainties and assumptions having an impact on the risk assessment should be explicitly considered at each step in the risk assessment and documented in a transparent manner’\n‘Responsibility for resolving the impact of uncertainty on the risk management decision lies with the risk manager, not the risk assessors’\n\nThese principles apply equally to the treatment of uncertainty in all areas of science and decisionmaking.\nIn general,\n\nassessors are responsible for characterising uncertainty and\ndecision-makers are responsible for resolving the impact of uncertainty on decisions. Resolving the impact on decisions means deciding whether and in what way decision-making should be altered to take account of the uncertainty.\n\nThe rational for this division of roles is:\n\nassessing scientific uncertainty requires scientific expertise, while\nresolving the impact of uncertainty on decision-making involves weighing the scientific assessment against other considerations, such as economics, law and societal values, which require different expertise and are also subject to uncertainty.\n\nAlthough risk assessment and risk management are conceptually distinct activities,\n\ninteraction between assessors and risk managers with regard to the specification of the question for assessment and expression of uncertainty in conclusions is useful.\n\n\nInformation required for decision-making\n\nUncertainty refers to limitations in knowledge, which are always present to some degree.\nDecision-makers need to know the range of possible answers, so they can consider whether any of them would imply risk of undesirable management consequences (e.g. adverse effects).\n\nFor some types of assessment, e.g. for regulated products, decision-makers need EFSA to provide an unqualified positive or negative conclusion to comply with the requirements of legislation, or of procedures established to implement legislation.\nIn general, the underlying assessment will be subject to at least some uncertainty, as is all scientific assessment. In such cases, therefore, the positive or negative conclusion refers to whether the level of certainty is sufficient for the purpose of decision-making, i.e. whether the assessment provides ‘practical certainty’\n\nInformation on the magnitude of uncertainty and the main sources of uncertainty is also important to inform decisions about whether it would be worthwhile to invest in obtaining further data or conducting more analysis, with the aim of reducing uncertainty.\n\nAll EFSA scientific assessments require at least a basic analysis of uncertainty.\n\nQuestions are posed to EFSA because the requestor does not know or is uncertain of the answer and that the amount of uncertainty affects decisions or actions they need to take.\nThe requestor seeks scientific advice from EFSA because they anticipate that this may reduce the uncertainty, or at least provide a more expert assessment of it.\nIf the uncertainty of the answer did not matter, then it would not be rational or economically justified for the requestor to pose the question to EFSA – the requestor would simply use their own judgement, or even a random guess.\nSo the fact that the question was asked implies that the amount of uncertainty matters for decision-making, and it follows that information about uncertainty is a necessary part of EFSA’s response.\nThis logic applies regardless of the nature or subject of the question, therefore providing information on uncertainty is relevant in all cases.\n\nIt follows that uncertainty analysis is needed in all EFSA scientific assessments, though the form and extent of that analysis and the form in which the conclusions are expressed should be adapted to the needs of each case, in consultation with decision-makers.\n\n\nTime and resource constraints\n\nConsideration of uncertainty is always required.\nTo be fit for purpose, EFSA’s guidance on uncertainty analysis includes options for different levels of resource and different timescales, and methods that can be implemented at different levels of detail/refinement, to fit different timescales and levels of resource.\nDecisions on how far to refine the assessment and whether to obtain additional data may be taken by assessors when they fall within the time and resources agreed for the assessment.\nUltimately, it is for decision-makers to decide when the characterisation of uncertainty is sufficient for decision-making and when further refinement is needed, taking into account the time and costs involved. ### Questions for assessment by EFSA  Questions for assessment by EFSA may be posed by the European Commission, the European Parliament, and EU Member State or by EFSA itself. Many questions to EFSA request assessment of consequences or current policy, conditions, practice or of consequences in alternative scenarios, e.g. under different risk management options.\nIt is important that the scenarios and consequences of interest are well-defined.\n\n\nAcceptable level of uncertainty\n\nComplete certainty is never possible.\nDeciding how much certainty is required or, equivalently, what level of uncertainty would warrant precautionary action, is the responsibility of decision-makers, not assessors.\nIt may be helpful if the decision-makers can specify in advance how much uncertainty is acceptable for a particular question because it has implications for what outputs should be produced from uncertainty analysis.\nOften, however, the decision-makers may not be able to specify in advance the level of certainty that is sought or the level of uncertainty that is acceptable, e.g. because this may vary from case to case depending on the costs and benefits involved. Another option is for assessors to provide results for multiple levels of certainty, so that decision-makers can consider at a later stage what level of uncertainty to accept.\nAlternatively, partial information on uncertainty may be sufficient for the decision-makers provided it meets or exceeds their required level of certainty.\n\n\nExpression of uncertainty in assessment conclusions\n\nRanges and probabilities are the natural metric for quantifying uncertainty and can be applied to any well-defined question or quantity of interest.\nThe question for assessment, or at least the eventual conclusion, needs to be well-defined, in order for its uncertainty to be assessed.\n\nIf qualitative terms are used to describe the degree of uncertainty, they should be clearly defined with objective scientific criteria. Specifically, the definition should identify the quantitative expression of uncertainty associated with the qualitative term as is done, for example, in the EFSA approximate probability scale LINK TO APPROX PROB SCALE\n\nFor some types of assessment, decision-makers need EFSA to provide an unqualified positive or negative conclusion. The positive or negative conclusion does not imply that there is complete certainty, since this is never achieved, but that the level of certainty is sufficient for the purpose of decision-making. In such cases, the assessment conclusion and summary may simply report the positive or negative conclusion but, for transparency, the justification for the conclusion should be documented somewhere, e.g. in the body of the assessment or an annex. If the level of certainty is not sufficient, then either the uncertainty should be expressed quantitatively, or assessors should report that their assessment is inconclusive and that they ‘cannot conclude’ on the question.\n\nWhen assessors do not quantify uncertainty, they must report that the probability of different answers is unknown and avoid using any language that could be interpreted as implying a probability statement as this would be misleading.\n\nThe assessors should avoid any verbal expressions that have risk management connotations in everyday language, such us ‘negligible’ and ‘concern’. When used without further definition, such expressions imply two simultaneous judgements: a judgement about the probability (or approximate probability) of adverse effects, and a judgement about the acceptability of that probability. The first of these judgements is within the remit of assessors, but the latter is not."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#approaches-to-expressing-uncertainty",
    "href": "pmguidance/pmanalysis.html#approaches-to-expressing-uncertainty",
    "title": "Principles of Uncertainty Analysis",
    "section": "Approaches to expressing uncertainty",
    "text": "Approaches to expressing uncertainty\n\nExpression of uncertainty requires two components: expression of the range of possible true answers to a question of interest, or a range of possible true values for a quantity of interest, and some expression of the probabilities of the different answers or values. Quantitative approaches express one or both of these components on a numerical scale. Qualitative approaches express them using words, categories or labels. They may rank the magnitudes of different uncertainties, and are sometimes given numeric labels, but they do not quantify the magnitudes of the uncertainties nor their impact on an assessment conclusion.\n\nA complete quantitative expression of uncertainty would specify all the answers or values that are considered possible and probabilities for them all. Partial quantitative expression provides only partial information on the probabilities and in some cases partial information on the possibilities (specifying a selection of possible answers or values). Partial quantitative expression requires less information or judgements but may be sufficient for decision-making in some assessments, whereas other cases may require fuller quantitative expression.\n\n\n\n\nTable 1:  Approximate probability scale \n \n  \n    Probability term \n    Subjective probability range \n    Additional options \n     \n  \n \n\n  \n    Almost certain \n    99-100% \n    More likely than not: >50% \n    Unable to give any probability: range is 0-100%. Report as 'inconclusive', 'cannot conclude' or 'unknown' \n  \n  \n    Extremely likely \n    95-99% \n   \n   \n  \n  \n    Very likely \n    90-95% \n   \n   \n  \n  \n    Likely \n    66-90% \n   \n   \n  \n  \n    About as likely as \n    33-66% \n     \n   \n  \n  \n    Unlikely \n    10-33% \n   \n   \n  \n  \n    Very unlikely \n    5-10% \n   \n   \n  \n  \n    Extremely unlikely \n    1-5% \n   \n   \n  \n  \n    Almost impossible \n    0-1% \n   \n   \n  \n\n\n\n\n\n\n\nQualitative expressions\n\nDescriptive expression: Uncertainty described in narrative text or characterised using verbal terms without any quantitative definition (Table 1).\nOrdinal scale: Uncertainty described by ordered categories, where the magnitude of the difference between categories is not quantified.\n\n\nQuantitative expressions\n\nIndividual values: Uncertainty partially quantified by specifying some possible values, without specifying what other values are possible or setting upper or lower limits.\nBound: Uncertainty partially quantified by specifying either an upper limit or a lower limit on a quantitative scale, but not both.\nRange: Uncertainty partially quantified by specifying both a lower and upper limit on a quantitative scale, without expressing the probabilities of different values within the limits.\nProbability: Uncertainty about a binary outcome (including the answer to a yes/no question) fully quantified by specifying the probability or approximate probability of both possible outcomes.\nProbability bound: Uncertainty about a non-variable quantity partially quantified by specifying a bound or range with an accompanying probability or approximate probability.\nDistribution: Uncertainty about a non-variable quantity fully quantified by specifying the probability of all possible values on a quantitative scale."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#the-role-of-quantitative-expressions-of-uncertainty",
    "href": "pmguidance/pmanalysis.html#the-role-of-quantitative-expressions-of-uncertainty",
    "title": "Principles of Uncertainty Analysis",
    "section": "The role of quantitative expressions of uncertainty",
    "text": "The role of quantitative expressions of uncertainty\nThe principal reasons for preferring quantitative expressions of uncertainty are as follows:\n\nQualitative expressions are ambiguous.\nDecision-making often depends on quantitative comparisons, for example, whether a risk exceeds some acceptable level, or whether benefits outweigh costs.\nIf assessors provide only a single answer or estimate and a qualitative expression of the uncertainty, decision-makers will have to make their own quantitative interpretation of how different the real answer or value might be. This judgement is better made by assessors, since they are better placed to understand the sources of uncertainty affecting the assessment and judge their effect on its conclusion.\nQualitative expressions often imply, or may be interpreted as implying, judgements about the implications of uncertainty for decision-making, which are outside the remit of EFSA.\nAssessors may assess uncertainty differently yet agree on a single qualitative expression, because they interpret it differently.\nExpressing uncertainties in terms of their quantitative impact on the assessment conclusion will reveal differences of opinion between experts working together on an assessment, enabling a more rigorous discussion and hence improving the quality of the final conclusion.\nIt has been demonstrated that people often perform poorly at judging combinations of probabilities. This implies they may perform poorly at judging how multiple uncertainties in an assessment combine. It may therefore be more reliable to divide the uncertainty analysis into parts and quantify uncertainty separately for those parts containing important sources of uncertainty, so that they can be combined by calculation.\nQuantifying uncertainty enables decision-makers to weigh the probabilities of different consequences against other relevant considerations.\n\n\nConcerns and objections to quantitative expressions of uncertainty\nMany concerns and objections to quantitative expression of uncertainty have been raised by various parties during the public consultation and trial period for this document and in the literature. These are listed in Box 2; many, not all, relate to the role of expert judgement in quantifying uncertainty. The Scientific Committee has considered these concerns carefully and concludes that all of them can be addressed, either by improved explanation of the principles involved or through the use of appropriate methods for obtaining and using quantitative expressions.\nBOX 2\n\n\nAssessors should express uncertainty in quantitative terms\n\nHaving considered the advantages of quantitative expression, and addressed the concerns, the Scientific Committee concludes that assessors should express in quantitative terms the combined effect of as many as possible of the identified sources of uncertainty, while recognising that how this is reported must be compatible with the requirements of decision-makers and legislation.\nAny sources of uncertainty that assessors are unable to include in their quantitative expression, for whatever reason, must be documented qualitatively and reported alongside it, because they will have significant implications for decision-making.\nTogether, the quantified uncertainty and the description of unquantified uncertainties provide the overall characterisation of uncertainty, and express it as unambiguously as is possible.\nThis recommended approach is thus consistent with the requirement of the FAO/WHO Codex Working Principles for Risk Analysis and the EFSA Guidance on Transparency from 2010, which state that uncertainty be ‘quantified to the extent that is scientifically achievable’.\n\n‘scientifically achievable’ should be interpreted as referring to including as many as possible of the identified sources of uncertainty within the quantitative assessment of overall uncertainty, and omitting only those which the assessors are unable to quantify.\n‘scientifically achievable’ does not mean that uncertainties should be quantified using the most sophisticated scientific methods available.\n\nThe recommended approach does not imply a requirement to quantify ‘unknown unknowns’ or ignorance. These type of sources of uncertainty are always potentially present, but cannot be included in assessment, as the assessors are unaware of them\n\n\nCommon concerns and objections to quantitative expression of uncertainty\n\nCommon concerns and objections to quantitative expression of uncertainty and how they are addressed by the approach developed in this document and the accompanying Guidance.\n\n\n\n\n\n\nQuantifying uncertainty requires complex computations, or excessive time or resource:\n\n\n\n\n\n\nmost of the options in the Guidance do not require complex computations, and the methods are scalable to any time and resource limitation, including urgent situations.\n\n\n\n\n\n\n\n\n\n\nQuantifying uncertainty requires extensive data:\n\n\n\n\n\n\nuncertainty can be quantified by expert judgement for any well-defined question or quantity, provided there is at least some relevant evidence.\n\n\n\n\n\n\n\n\n\n\nData are preferable to expert judgement:\n\n\n\n\n\n\nthe Guidance recommends use of relevant data where available.\n\n\n\n\n\n\n\n\n\n\nSubjectivity is unscientific:\n\n\n\n\n\n\nAll judgement is subjective, and judgement is a necessary part of all scientific assessment. Even when good data are available, expert judgement is involved in evaluating and analysing them, and when using them in risk assessment.\n\n\n\n\n\n\n\n\n\n\nSubjective judgements are guesswork and speculation:\n\n\n\n\n\n\nall judgements in EFSA assessments will be based on evidence and reasoning, which will be documented transparently.\n\n\n\n\n\n\n\n\n\n\nExpert judgement is subject to psychological biases:\n\n\n\n\n\n\nEFSA’s guidance on uncertainty analysis and expert knowledge elicitation use methods designed to counter those biases.\n\n\n\n\n\n\n\n\n\n\nQuantitative judgements are over-precise:\n\n\n\n\n\n\nEFSA’s methods produce judgements that reflect the experts’ uncertainty – if they feel they are over-precise, they should adjust them accordingly.\n\n\n\n\n\n\n\n\n\n\nUncertainty is exaggerated:\n\n\n\n\n\n\nidentify your reasons for thinking the uncertainty is exaggerated, and revise your judgements to take them into account.\n\n\n\n\n\n\n\n\n\n\nThere are too many uncertainties:\n\n\n\n\n\n\nwhenever experts draw conclusions, they are necessarily making judgements about all the uncertainties they are aware of. The Guidance provides methods for assessing uncertainties collectively that increase the rigour and transparency of those judgements.\n\n\n\n\n\n\n\n\n\n\nProbability judgements are themselves uncertain:\n\n\n\n\n\n\ntake the uncertainty of your judgement into account as part of the judgement, e.g. by giving a range, or making it wider.\n\n\n\n\n\n\n\n\n\n\nGiving precise quantiles for uncertainty is over-confident:\n\n\n\n\n\n\nthe quantiles will not be treated as precise, but as a step in deriving a distribution for you to review and adjust. If there is concern about the choice of distribution, its impact on the analysis can be assessed by sensitivity analysis. Alternatively, approximate probabilities could be used.\n\n\n\n\n\n\n\n\n\n\nThere are some uncertainties I cannot make a probability judgement for:\n\n\n\n\n\n\nin principle, probability judgements can be given for all well-defined questions or quantities. However, the Guidance recognises that experts may be unable to make probability judgements for some uncertainties, and provides options for dealing with this.\n\n\n\n\n\n\n\n\n\n\nDifferent experts will make different judgements:\n\n\n\n\n\n\nthis is expected and inevitable, whether the judgements are quantitative or not. An advantage of quantitative expression is that those differences are made explicit and can be discussed, leading to better conclusions. These points apply to experts working on the same assessment, and also to different assessments of the same question by different experts or institutions.\n\n\n\n\n\n\n\n\n\n\nI cannot give a probability for whether a model is correct:\n\n\n\n\n\n\nno model is entirely correct. Model uncertainty is better expressed by making a probability judgement for how different the model result might be from the real value.\n\n\n\n\n\n\n\n\n\n\nUncertainty should be addressed by conservative assumptions:\n\n\n\n\n\n\nchoosing a conservative assumption involves two judgements – the probability that the assumption is valid, and the acceptability of that probability. The Guidance improves the rigour and transparency of the first judgement, providing a better basis for the second (which is part of risk management).\n\n\n\n\n\n\n\n\n\n\nProbabilities cannot be given for qualitative conclusions:\n\n\n\n\n\n\nProbability judgements can be made for any well-defined conclusion, and all EFSA conclusions should be well-defined.\n\n\n\n\n\n\n\n\n\n\nYou cannot make judgements about unknown unknowns:\n\n\n\n\n\n\nno such judgements are implied. All scientific advice is conditional on assumptions about unknown unknowns.\n\n\n\n\n\n\n\n\n\n\nUncertainty is unquantifiable by definition:\n\n\n\n\n\n\nthis is the Knightian view. The Guidance uses subjective probability, which Knight recognised as an option.\n\n\n\n\n\n\n\n\n\n\nProbabilities cannot be given unless all the possibilities can be specified:\n\n\n\n\n\n\nprovided an answer to a question is well-defined, a probability judgement can be made for it without specifying or knowing all possible alternative answers. However, assessors should guard against a tendency to underestimate the probability of other answers when they are not differentiated.\n\n\n\n\n\n\n\n\n\n\nNone of the ranges in the approximate probability scale properly represent my judgement:\n\n\n\n\n\n\nspecify a range that does.\n\n\n\n\n\n\n\n\n\n\nLack of evidence:\n\n\n\n\n\n\nif there really is no evidence, no probability judgement can be made – and no scientific conclusion can be drawn.  Another way to see it, is that if the experts can make a conclusion (that is not inconclusive), they should also be able to express their level of certainty about it.\n\n\n\n\n\n\n\n\n\n\nIt is not valid to combine probabilities derived from data with probabilities derived by expert judgement:\n\n\n\n\n\n\nthere is a well-established theoretical basis for using probability calculations to combine probability judgements elicited from experts (including probability judgements informed by non Bayesian statistical analysis) with probabilities obtained from Bayesian statistical analysis of data.\n\n\n\n\n\n\n\n\n\n\nThe result of the uncertainty analysis is incompatible with, or undermines, our conclusion:\n\n\n\n\n\n\nreconsider both the uncertainty analysis and the conclusion, and revise one or both so they (a) match and (b) properly represent what the science supports. A justifiable conclusion takes account of uncertainty, so there should be no inconsistency.\n\n\n\n\n\n\n\n\n\n\nDecision-makers require us to say whether a thing is safe or not safe, not give a probability for being safe:\n\n\n\n\n\n\n‘safe’ implies some acceptable level of certainty, so if that is defined then positive or negative conclusion may be given without qualification.\n\n\n\n\n\n\n\n\n\n\nRisk managers and the public do not want to know about uncertainty:\n\n\n\n\n\n\nactually many do, and as a matter of principle, decision-makers need information on uncertainty to make rational decisions.\n\n\n\n\n\n\n\n\n\n\nCommunicating uncertainty will undermine public confidence in scientific assessment:\n\n\n\n\n\n\nsome evidence supports this, but other evidence suggests communicating uncertainty can increase confidence. EFSA’s approach on communicating uncertainty is designed to achieve the latter."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#the-role-of-qualitative-expressions-of-uncertainty",
    "href": "pmguidance/pmanalysis.html#the-role-of-qualitative-expressions-of-uncertainty",
    "title": "Principles of Uncertainty Analysis",
    "section": "The role of qualitative expressions of uncertainty",
    "text": "The role of qualitative expressions of uncertainty\n\nQualitative methods in uncertainty analysis are specifically recommended for the following purposes:\n\nAs a simple approach for prioritising uncertainties.\nAt intermediate points in an uncertainty analysis, to characterise individual sources of uncertainty qualitatively, as an aid to quantifying their combined impact by probability judgement. This may be useful either for individual parts of the uncertainty analysis, or as a preliminary step when characterising the overall uncertainty of the conclusion.\nWhen quantifying uncertainty by expert judgement, and when communicating the results of that, it may in some cases be helpful to use an approximate probability scale with accompanying qualitative descriptors\n (verbal expressions).\nAt the end of uncertainty analysis, for describing uncertainties that the assessors are unable to include in their quantitative evaluation.\nWhen reporting the assessment, for expressing the assessment conclusion in qualitative terms when this is required by decision-makers or legislation.\n\n\n\n\n\n\n\n\nef1d0f43000f91535a0df8f8da30f176634eb690 # Key concepts"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#well-defined-questions-and-quantities-of-interest",
    "href": "pmguidance/pmanalysis.html#well-defined-questions-and-quantities-of-interest",
    "title": "Principles of Uncertainty Analysis",
    "section": "Well-defined questions and quantities of interest",
    "text": "Well-defined questions and quantities of interest"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#conditional-nature-of-uncertainty",
    "href": "pmguidance/pmanalysis.html#conditional-nature-of-uncertainty",
    "title": "Principles of Uncertainty Analysis",
    "section": "Conditional nature of uncertainty",
    "text": "Conditional nature of uncertainty"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#uncertainty-and-variability",
    "href": "pmguidance/pmanalysis.html#uncertainty-and-variability",
    "title": "Principles of Uncertainty Analysis",
    "section": "Uncertainty and variability",
    "text": "Uncertainty and variability"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#dependencies",
    "href": "pmguidance/pmanalysis.html#dependencies",
    "title": "Principles of Uncertainty Analysis",
    "section": "Dependencies",
    "text": "Dependencies"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#models-and-model-uncertainty",
    "href": "pmguidance/pmanalysis.html#models-and-model-uncertainty",
    "title": "Principles of Uncertainty Analysis",
    "section": "Models and model uncertainty",
    "text": "Models and model uncertainty"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#evidence-agreement-confidence-and-weight-of-evidence",
    "href": "pmguidance/pmanalysis.html#evidence-agreement-confidence-and-weight-of-evidence",
    "title": "Principles of Uncertainty Analysis",
    "section": "Evidence, agreement, confidence and weight of evidence",
    "text": "Evidence, agreement, confidence and weight of evidence"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#influence-sensitivity-and-prioritisation-of-uncertainties",
    "href": "pmguidance/pmanalysis.html#influence-sensitivity-and-prioritisation-of-uncertainties",
    "title": "Principles of Uncertainty Analysis",
    "section": "Influence, sensitivity and prioritisation of uncertainties",
    "text": "Influence, sensitivity and prioritisation of uncertainties"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#conservative-assessments",
    "href": "pmguidance/pmanalysis.html#conservative-assessments",
    "title": "Principles of Uncertainty Analysis",
    "section": "Conservative assessments",
    "text": "Conservative assessments"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#expert-judgement",
    "href": "pmguidance/pmanalysis.html#expert-judgement",
    "title": "Principles of Uncertainty Analysis",
    "section": "Expert judgement",
    "text": "Expert judgement"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#probability",
    "href": "pmguidance/pmanalysis.html#probability",
    "title": "Principles of Uncertainty Analysis",
    "section": "Probability",
    "text": "Probability"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#overall-uncertainty",
    "href": "pmguidance/pmanalysis.html#overall-uncertainty",
    "title": "Principles of Uncertainty Analysis",
    "section": "Overall uncertainty",
    "text": "Overall uncertainty\n\nIt is therefore important to quantify the overall impact of as many as possible of the identified uncertainties, and identify any that cannot be quantified. The most direct way to achieve this is to try to quantify the overall impact of all identified uncertainties, as this will reveal any that cannot be quantified."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#unquantified-uncertainties",
    "href": "pmguidance/pmanalysis.html#unquantified-uncertainties",
    "title": "Principles of Uncertainty Analysis",
    "section": "Unquantified uncertainties",
    "text": "Unquantified uncertainties"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#conditionality-of-assessments",
    "href": "pmguidance/pmanalysis.html#conditionality-of-assessments",
    "title": "Principles of Uncertainty Analysis",
    "section": "Conditionality of assessments",
    "text": "Conditionality of assessments"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#key-principles-when-conducting-case-specific-assessments",
    "href": "pmguidance/pmanalysis.html#key-principles-when-conducting-case-specific-assessments",
    "title": "Principles of Uncertainty Analysis",
    "section": "Key principles when conducting case-specific assessments",
    "text": "Key principles when conducting case-specific assessments\n\n\n\n\n\n\n\nWhat is a case-specific assessment?\n\n\n\nA case-specific assessment is needed when there is no standardised procedure for the type of assessment in hand, and when parts of the assessment use standardised procedure but other parts are case-specific or deviate from the standardised procedure (e.g. for refinement or urgency), and for calibrating standardised procedures when they are first established or revised.\n\n\n\nThe uncertainty analysis should start at a level that is appropriate to the assessment in hand. For assessments where data to quantify uncertainty is available and/or where suitable quantitative methods are already established, this may be included in the initial assessment. In other assessments, it may be best to start with a simple approach, unless it is evident at the outset that more complex approaches are needed.\nUncertainty analysis should be refined as far as is needed to inform decision-making. – This point is reached either when there is sufficient certainty about the question or quantity of interest for the decision-makers to make a decision with the level of certainty they require, or – if it becomes apparent that achieving the desired level of uncertainty is unfeasible or too costly and the decision-makers decide instead to manage the uncertainty without further refinement of the analysis.\nRefinements of the uncertainty analysis using more complex or resource-intensive methods and options should be targeted on those sources of uncertainty where they will contribute most efficiently to improving the characterisation of uncertainty, taking account of their influence on the assessment conclusion and the cost and feasibility of the refinement.\nThe characterisation of overall uncertainty must integrate the contributions of identified sources of uncertainties that have been expressed in different ways."
  },
  {
    "objectID": "pmguidance/pmanalysis.html#key-principles-when-using-standardise-procedures",
    "href": "pmguidance/pmanalysis.html#key-principles-when-using-standardise-procedures",
    "title": "Principles of Uncertainty Analysis",
    "section": "Key principles when using standardise procedures",
    "text": "Key principles when using standardise procedures\n\n\n\n\n\n\n\nWhat is a standardised assessment procedure?\n\n\n\nStandardised assessment procedures with accepted provision for uncertainty are common in many areas of EFSA’s work, especially for regulated products, and are subject to periodic review. ULLRIKA TO PUT MORE HERE"
  },
  {
    "objectID": "pmguidance/pmanalysis.html#key-principles-for-urgent-assessments",
    "href": "pmguidance/pmanalysis.html#key-principles-for-urgent-assessments",
    "title": "Principles of Uncertainty Analysis",
    "section": "Key principles for urgent assessments",
    "text": "Key principles for urgent assessments\n\n\n\n\n\n\n\nWhat is an urgent assessment?\n\n\n\nTO BE TUNED _ TAKE FRO GLOSSARY?\nIn some situations, e.g. emergencies, EFSA may be required to provide an urgent assessment in very limited time and the approach taken must be adapted accordingly. Uncertainty is generally increased in such situations, and may be a major driver for decision-making. Characterisation of uncertainty is therefore still necessary, despite the urgency of the assessment. However, the approach to providing it must be scaled to fit within the time and resources available."
  },
  {
    "objectID": "pmguidance/pmcommunication.html",
    "href": "pmguidance/pmcommunication.html",
    "title": "Principles of Uncertainty Communication",
    "section": "",
    "text": "About this tutorial"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "Methods for Uncertainty Analysis",
    "section": "",
    "text": "Methods page"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Video transcript"
  },
  {
    "objectID": "intro.html#about",
    "href": "intro.html#about",
    "title": "Introduction",
    "section": "About",
    "text": "About\nThis tutorial is provided within OC/EFSA/KNOW/2022/01 Lot 2 Trainings on horizontal scientific assessment methodologies EFSA training.\nThis page was created by Ullrika Sahlin and Dmytro Perepolkin."
  },
  {
    "objectID": "communication.html",
    "href": "communication.html",
    "title": "Communication of Uncertainty",
    "section": "",
    "text": "Welcome to the page on Uncertainty Communication!\nThe pupose of the section is to introduce you to the “Guidance on Communication of Uncertainty in Scientific Assessments”. The material for this page is heavy based on the Principles of Uncertainty Communication and we strongly recomend that you start your journey into the world of uncertainty communication there.\nWe divided the material on this page into two sections: there’s a section for uncertainty communicators and another one for the assessors. The presentation of the material also varies by the preparation level of the target audience. The material for the Communicators covers the Entry and Informed levels, while the Assessors are encouraged to refer to guidance for communication on the Informed and Technical levels.\nUse one of the buttons below to proceed to the next page, where you will be presented with a communication checklist and the corresponding recommendations addressing the various aspects of uncertainty communication for the different audience levels.\n\n\nIntroduction to the page. Information about the UC GD and that this is the GD based on the principles from the UC GD and that we recommend looking at those before going through the UC GD page. Instructions on how to explore the page. Recommendations when it can be useful to consult it when you are working with an assessment.\n\nI am:\n\n\n\n\n%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([Communicator])\n  B([Assessor])\n  click A \"comguidance/communicator.html\" \"Go to Communicator page\"\n  click B \"comguidance/assessor.html\" \"Go to Assessor page\"\n\n\n\n\n\n\n\n\nThe introduction section also provides an overview of risk communication in EFSA, covering the main strategies and the criteria for proper audience targeting. We introduce the expressions of uncertainty used at EFSA and invite the user to select one of the two sections to proceed\nThe rest of the content on the page is split between the communicator, and the assessor role. The user has the opportunity to select the other role and explore the content in the respective section. The Communicator section provides guidance for communication on the entry-level and the informed level, while the Assessor section provides guidance for the technical level.\nFinally, both the Communicator and the Assessor roles share the section for the Specific Guidances, consisting of the 9 types of expressions of uncertainty as shown in Figure 4. The content of the Specific Guidances varies depending on the role (the Communicator is shows the entry and informed level and the Assessor is shown the technical level)\nEach of the specific guidances (for assessors) is accompanied by a short text and links to best-practice examples (i.e. where these Specific Guidances were followed) in the implementation section (below).\nWe will also refer to additional information in the Principles and Methods opinion on reporting and communicating uncertainties (Ch 15 and 16)."
  },
  {
    "objectID": "implementationmethods.html",
    "href": "implementationmethods.html",
    "title": "Methods for Uncertainty Analysis",
    "section": "",
    "text": "Introduction to the page. Information about this page collects examples of implementation of the UA and UC GDs. Instructions on how to explore the page. How we have chosen the examples. A reminder that this is an extraction of examples and that there are more on EFSA website.\n\nHere we will have the interactive data table of examples. Currently, we plan to have the following fields in the table:\n\nTitle\nDOI\nPanel\nExpression of uncertainty (from the nine expressions)\nQuantitative method for uncertainty analysis\nQualitative method for uncertainty analysis\nDescription\n\nThe dataframe below is provided as a placeholder."
  },
  {
    "objectID": "principles.html",
    "href": "principles.html",
    "title": "Principles and methods behind the guidances",
    "section": "",
    "text": "Welcome to the page on Principles and Methods for the Uncertainty Analysis and Communication of Uncertainty guidances!\nIn this sections you can learn more about the underlying concepts behind the two main guidance documents.\nThe concepts described on this page are primarily coming from the Principles and Methods Document (pointing to the right), as well as the Section 3 in the Communication Guidance (pointing to the right).\nOn the left hand side you can see the side menu which contains the links to the pages for respective sections. The methods for uncertainty analysis are discussed separately. You might want to check that page out when you are unsure about certain method or want to identify an appropriate method of handling uncertainty appropriate for your situation.\nLook around and make yourself at home here, because you might come back here after you’ve explored the rest of the tutorial for some in-depth insights! See you!"
  },
  {
    "objectID": "uncertaintyanalysis.html",
    "href": "uncertaintyanalysis.html",
    "title": "Uncertainty Analysis Guidance",
    "section": "",
    "text": "The recommended approach to uncertainty analysis depends on the nature of the scientific assessment in hand. The video below introduces the different kinds of assessments and the associated process.\n\nIdentify which of the following types your assessment most corresponds to and then proceed to the corresponding section for guidance specific to that type.\n\n\n\n\n%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  A([Standardized</br>Assessments])\n  B([Case-specific</br>assessments])\n  click A \"uaguidance/figure1.html\" \"A standardised assessment follows a pre-established standardised procedure that covers every step of the assessment\"\n  click B \"uaguidance/figure5.html\" \"Scientific assessments where there is no pre-established standardised procedure, so the assessors have to develop an assessment plan that is specific to the case in hand. Standardised elements (e.g. default values) may be used for some parts of the assessment, but other parts require case-specific approaches.\"\n\n\n\n\n\n\n\n\n\n\n\n\n%%{init:{\"theme\":\"base\", \"themeVariables\": {\"primaryColor\":\"white\", \"secondaryColor\":\"white\", \"tertiaryColor\":\"white\", \"mainBkg\":\"#f2f2f2\", \"nodeBorder\":\"#7F7F7F\", \"clusterBkg\":\"#FFF9FB\"}}}%%\nflowchart TB\n  C([Urgent</br>assessments])\n  D([Development or revision</br>of guidance documents])\n  click C \"uaguidance/figure11.html\" \"Assessments that, for any reason, must be completed within an unusually short period of time or with unusually limited resources, and therefore require streamlined approaches to both assessment and uncertainty analysis\"\n  click D \"uaguidance/figure12.html\" \"Especially (but not only) those that describe existing standardised procedures or establish new ones\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearn more about:\n\n\n\n\nIdentifying uncertainties affecting the assessment\nPrioritizing uncertainties within the assessment\nDividing the uncertainty analysis into parts\nEnsuring that the questions or quantities of interest are well-defined.\nCharacterizing uncertainty for parts of the uncertainty analysis\nCombining uncertainty from different parts of the uncertainty analysis\nCharacterising overall uncertainty\nPrioritising uncertainties for future investigation.\nReporting uncertainty analysis"
  }
]